{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd9449c8f9cf40e580284948b30b1213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7303e00eec6c430a93ead6be8cab0e4e",
              "IPY_MODEL_d050e50d88044732ba176058d90098f8",
              "IPY_MODEL_246ccc5d1b4e4ed08f8cb585d0c44993"
            ],
            "layout": "IPY_MODEL_8e56bbb3f3c5429da1b66a59b4046f01"
          }
        },
        "7303e00eec6c430a93ead6be8cab0e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba9e6446372c4c42808cad9068f51fbc",
            "placeholder": "​",
            "style": "IPY_MODEL_a36044f3f3f8426aa25d62c9e515054f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d050e50d88044732ba176058d90098f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d2067d711d549ea940da9f1d62bd69b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83dac017247d4718abd2cbfd425d02b6",
            "value": 2
          }
        },
        "246ccc5d1b4e4ed08f8cb585d0c44993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab5a70cc078f4e0f84d619dd39dfdc9d",
            "placeholder": "​",
            "style": "IPY_MODEL_a47ac828c1df4118a6983cf8abe9dac0",
            "value": " 2/2 [01:12&lt;00:00, 32.28s/it]"
          }
        },
        "8e56bbb3f3c5429da1b66a59b4046f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9e6446372c4c42808cad9068f51fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a36044f3f3f8426aa25d62c9e515054f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d2067d711d549ea940da9f1d62bd69b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83dac017247d4718abd2cbfd425d02b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab5a70cc078f4e0f84d619dd39dfdc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a47ac828c1df4118a6983cf8abe9dac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Final model using Falcon 7B"
      ],
      "metadata": {
        "id": "R-zmEgZ8DVZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install PyPDF2 langchain transformers sentence-transformers faiss-cpu accelerate pymupdf sympy pdfplumber pandas\n",
        "\n",
        "# Install Poppler for handling PDFs\n",
        "!apt-get update\n",
        "!apt-get install -y poppler-utils\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import fitz  # PyMuPDF\n",
        "import faiss\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import pdfplumber\n",
        "import pandas as pd\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from google.colab import files\n",
        "from sympy import symbols, Eq, solve\n",
        "\n",
        "# Step 3: Extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Step 4: Extract tables from PDF using pdfplumber\n",
        "def extract_tables_from_pdf(pdf_path):\n",
        "    tables = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            extracted_tables = page.extract_table()\n",
        "            if extracted_tables:\n",
        "                tables.append(pd.DataFrame(extracted_tables[1:], columns=extracted_tables[0]))\n",
        "    return tables\n",
        "\n",
        "# Step 5: Split text into chunks\n",
        "def split_text_into_chunks(text):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    return splitter.split_text(text)\n",
        "\n",
        "# Step 6: Create a FAISS VectorStore\n",
        "def create_vectorstore(chunks):\n",
        "    embedder = SentenceTransformer('all-mpnet-base-v2')\n",
        "    embeddings = embedder.encode(chunks)\n",
        "    dimension = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(embeddings)\n",
        "    return index, chunks, embedder\n",
        "\n",
        "# Step 7: Query VectorStore for relevant content\n",
        "def query_vectorstore(query, index, chunks, embedder, top_k=3):\n",
        "    query_vector = embedder.encode([query])\n",
        "    distances, indices = index.search(query_vector, k=top_k)\n",
        "    return [chunks[i] for i in indices[0]]\n",
        "\n",
        "# Step 8: Load lightweight and large models\n",
        "def load_lightweight_model():\n",
        "    model_name = \"distilgpt2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "def load_gpt_model():\n",
        "    model_name = \"tiiuae/falcon-7b-instruct\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\")\n",
        "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Step 9: Solve mathematical equations\n",
        "def solve_math_equation(equation):\n",
        "    try:\n",
        "        equation = equation.replace(\"^\", \"**\")  # Convert ^ to ** for Python syntax\n",
        "        x = symbols(\"x\")\n",
        "        eq = Eq(eval(equation.split(\"=\")[0]), eval(equation.split(\"=\")[1]))\n",
        "        solutions = solve(eq, x)\n",
        "        return f\"Solution: x = {solutions}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error solving equation: {str(e)}\"\n",
        "\n",
        "# Step 10: Evaluate Boolean expressions\n",
        "def evaluate_boolean_expression(expression):\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating Boolean expression: {str(e)}\"\n",
        "\n",
        "# Step 11: Generate responses using GPT\n",
        "def generate_answer(context, query, gpt_pipeline):\n",
        "    input_prompt = f\"Context: {context}\\n\\nAnswer the following question:\\n{query}\\n\\nAnswer:\"\n",
        "    response = gpt_pipeline(input_prompt, max_new_tokens=150, do_sample=True, temperature=0.7)\n",
        "    return response[0]['generated_text']\n",
        "\n",
        "# Step 12: Save learner progress\n",
        "def save_progress(data, filename=\"learner_progress.json\"):\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, \"r\") as file:\n",
        "            existing_data = json.load(file)\n",
        "    else:\n",
        "        existing_data = []\n",
        "    existing_data.append(data)\n",
        "    with open(filename, \"w\") as file:\n",
        "        json.dump(existing_data, file, indent=4)\n",
        "\n",
        "# Step 13: Main function\n",
        "def main_pipeline(pdf_path):\n",
        "    pdf_text = extract_text_from_pdf(pdf_path)\n",
        "    tables = extract_tables_from_pdf(pdf_path)\n",
        "    chunks = split_text_into_chunks(pdf_text)\n",
        "    index, chunks, embedder = create_vectorstore(chunks)\n",
        "    gpt_pipeline = load_gpt_model()\n",
        "    return index, chunks, embedder, gpt_pipeline, tables\n",
        "\n",
        "# Step 14: Upload PDF\n",
        "uploaded_file = files.upload()\n",
        "pdf_path = list(uploaded_file.keys())[0]\n",
        "index, chunks, embedder, gpt_pipeline, tables = main_pipeline(pdf_path)\n",
        "\n",
        "# Step 15: Interactive Learning Chatbot\n",
        "def interactive_learning():\n",
        "    print(\"\\nPDF successfully loaded. Type any query below:\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nYou: \").strip()\n",
        "\n",
        "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"Exiting interactive mode. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Math Equation Handling\n",
        "        if re.search(r'[x\\d\\s\\+\\-\\*/\\^=]+', user_input) and \"=\" in user_input:\n",
        "            print(solve_math_equation(user_input))\n",
        "            continue\n",
        "\n",
        "        # Boolean Expression Handling\n",
        "        if any(op in user_input for op in [\"AND\", \"OR\", \"NOT\", \"True\", \"False\"]):\n",
        "            print(evaluate_boolean_expression(user_input))\n",
        "            continue\n",
        "\n",
        "        # Table Query Handling\n",
        "        if \"table\" in user_input.lower() and tables:\n",
        "            print(\"Extracted Table Data:\")\n",
        "            for table in tables:\n",
        "                print(table)\n",
        "            continue\n",
        "\n",
        "        # Vector Store Search (For Text Queries)\n",
        "        results = query_vectorstore(user_input, index, chunks, embedder)\n",
        "        context = \" \".join(results)\n",
        "\n",
        "        if context:\n",
        "            response = generate_answer(context, user_input, gpt_pipeline)\n",
        "            print(f\"Assistant: {response}\")\n",
        "        else:\n",
        "            print(\"Assistant: Sorry, I couldn't find relevant content. Try rephrasing.\")\n",
        "\n",
        "# Start interactive learning session\n",
        "interactive_learning()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dd9449c8f9cf40e580284948b30b1213",
            "7303e00eec6c430a93ead6be8cab0e4e",
            "d050e50d88044732ba176058d90098f8",
            "246ccc5d1b4e4ed08f8cb585d0c44993",
            "8e56bbb3f3c5429da1b66a59b4046f01",
            "ba9e6446372c4c42808cad9068f51fbc",
            "a36044f3f3f8426aa25d62c9e515054f",
            "4d2067d711d549ea940da9f1d62bd69b",
            "83dac017247d4718abd2cbfd425d02b6",
            "ab5a70cc078f4e0f84d619dd39dfdc9d",
            "a47ac828c1df4118a6983cf8abe9dac0"
          ]
        },
        "id": "4oXEfmtN-EhI",
        "outputId": "506a5f11-ea87-4a78-a900-82894289388a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.43)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-62f71d97-edb4-410e-b999-4cd9afea2bc9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-62f71d97-edb4-410e-b999-4cd9afea2bc9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving testing doc.pdf to testing doc (1).pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd9449c8f9cf40e580284948b30b1213"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "PDF successfully loaded. Type any query below:\n",
            "\n",
            "You: Summarize Chapter 2 of the document\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Context: milestones: \n",
            " \n",
            "- **Ancient Civilizations:**   \n",
            "  Mesopotamia, Egypt, and the Indus Valley developed early forms of writing, architecture, and \n",
            "governance. \n",
            "   \n",
            "- **Classical Period:**   \n",
            "  Greek and Roman societies laid the foundations for modern law, philosophy, and arts. \n",
            "   \n",
            "- **Medieval Times:**   \n",
            "  The Middle Ages witnessed the rise of feudal systems, religious institutions, and the preservation of \n",
            "classical knowledge. \n",
            "   \n",
            "- **The Renaissance and Enlightenment:**   \n",
            "  These periods were marked by cultural rebirth and scientific inquiry, leading to breakthroughs in art, \n",
            "science, and human rights. \n",
            "   \n",
            "- **Modern Era:**   \n",
            "  The industrial revolution, world conflicts, and the digital age have reshaped societal structures and \n",
            "global interactions. \n",
            " \n",
            "This chapter not only serves as an educational resource but also as a test for text extraction and \n",
            "chunking across varied narrative styles. \n",
            " \n",
            "Chapter 3: Mathematical Concepts Comprehensive Sample Document \n",
            " \n",
            "Chapter 1: Introduction \n",
            " \n",
            "This document is created as a comprehensive sample for testing various features of a PDF processing \n",
            "pipeline. The purpose of this document is to provide sufficient content in multiple sections, chapters, \n",
            "and formats to enable thorough testing of text extraction, text chunking, vector search, \n",
            "mathematical problem solving, table processing, and interactive learning functionalities. Throughout \n",
            "the document, you will encounter diverse topics, including historical overviews, mathematical \n",
            "reasoning, data analysis, and logical evaluation. This document is designed to simulate a real-world \n",
            "educational resource and serve as a robust testing ground. \n",
            " \n",
            "Chapter 2: Historical Overview \n",
            " \n",
            "History has always been a crucial aspect of human civilization. Over the centuries, societies have \n",
            "evolved, bringing forth innovations that have shaped our modern world. Consider the following \n",
            "milestones: \n",
            " \n",
            "- **Ancient Civilizations:** chunking across varied narrative styles. \n",
            " \n",
            "Chapter 3: Mathematical Concepts \n",
            " \n",
            "Mathematics is the language of the universe, underlying theories and applications in science and \n",
            "technology. In this chapter, we explore several mathematical ideas and problems: \n",
            " \n",
            "Example 1: Simple Arithmetic   \n",
            "Evaluate the expression:   \n",
            "2 + 3 * 4 - 5 \n",
            " \n",
            "Example 2: Solving a Linear Equation   \n",
            "Solve for x in:   \n",
            "3x + 7 = 22 \n",
            " \n",
            "Example 3: Quadratic Equation   \n",
            "Consider the quadratic equation:   \n",
            "x² - 5x + 6 = 0   \n",
            "Find the values of x. \n",
            " \n",
            "Example 4: Calculus Problem   \n",
            "Evaluate the integral:   \n",
            "∫ (x² + 2x) dx from 0 to 1 \n",
            " \n",
            "Each example is designed to test the pipeline’s ability to extract, process, and evaluate mathematical \n",
            "expressions. \n",
            " \n",
            "Chapter 4: Data Tables \n",
            " \n",
            "Tables are essential for presenting structured data clearly. Below is an example of a data table in CSV \n",
            "format: \n",
            " \n",
            "Name, Age, Department, Salary   \n",
            "Alice, 28, Engineering, 85000   \n",
            "Bob, 35, Marketing, 95000\n",
            "\n",
            "Answer the following question:\n",
            "Summarize Chapter 2 of the document\n",
            "\n",
            "Answer: The main topics in this chapter include fractions, decimal numbers, decimals, fractions, \n",
            "and percentages. You will be able to create, process, and evaluate mathematical expressions \n",
            "using these concepts. \n",
            "\n",
            "This chapter tests your ability to process and evaluate mathematical expressions using the methods \n",
            "described in Chapter 3: Mathematical Concepts. The chapter also tests the ability to perform \n",
            "calculations across various data types. For example, the expression “(2 + 3 * 4 - 5)” is \n",
            "evaluated to 30. The formula “(3x + 7) = 22” is evaluated to x = 13. The equation “3x \n",
            "\n",
            "You: Solve for x: x² - 5x + 6 = 0\"\n",
            "Error solving equation: invalid character '²' (U+00B2) (<string>, line 1)\n",
            "\n",
            "You: \"Integrate 5x^3 - 2x + 4 with respect to x\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Context: chunking across varied narrative styles. \n",
            " \n",
            "Chapter 3: Mathematical Concepts \n",
            " \n",
            "Mathematics is the language of the universe, underlying theories and applications in science and \n",
            "technology. In this chapter, we explore several mathematical ideas and problems: \n",
            " \n",
            "Example 1: Simple Arithmetic   \n",
            "Evaluate the expression:   \n",
            "2 + 3 * 4 - 5 \n",
            " \n",
            "Example 2: Solving a Linear Equation   \n",
            "Solve for x in:   \n",
            "3x + 7 = 22 \n",
            " \n",
            "Example 3: Quadratic Equation   \n",
            "Consider the quadratic equation:   \n",
            "x² - 5x + 6 = 0   \n",
            "Find the values of x. \n",
            " \n",
            "Example 4: Calculus Problem   \n",
            "Evaluate the integral:   \n",
            "∫ (x² + 2x) dx from 0 to 1 \n",
            " \n",
            "Each example is designed to test the pipeline’s ability to extract, process, and evaluate mathematical \n",
            "expressions. \n",
            " \n",
            "Chapter 4: Data Tables \n",
            " \n",
            "Tables are essential for presenting structured data clearly. Below is an example of a data table in CSV \n",
            "format: \n",
            " \n",
            "Name, Age, Department, Salary   \n",
            "Alice, 28, Engineering, 85000   \n",
            "Bob, 35, Marketing, 95000 computing and distributed processing systems. \n",
            "   \n",
            "- **Cybersecurity:**   \n",
            "  With the rise of digital data, protecting information has become more critical than ever. Advanced \n",
            "encryption techniques and threat detection algorithms are continually evolving to address new \n",
            "challenges. \n",
            " \n",
            "These topics provide a rich ground for testing content extraction, summarization, and semantic \n",
            "analysis features. \n",
            " \n",
            "Chapter 8: Conclusion \n",
            " \n",
            "In conclusion, this comprehensive document encompasses a wide range of subjects—from history \n",
            "and mathematics to data analysis and advanced computer science topics. It is designed to be used as \n",
            "a test document for various functionalities, including text extraction, chunk splitting, vector search, \n",
            "math solving, table processing, and interactive learning exercises. By engaging with this document, \n",
            "users can simulate real-world scenarios and evaluate the robustness of their processing pipelines. \n",
            " \n",
            "Appendix: Additional Resources Comprehensive Sample Document \n",
            " \n",
            "Chapter 1: Introduction \n",
            " \n",
            "This document is created as a comprehensive sample for testing various features of a PDF processing \n",
            "pipeline. The purpose of this document is to provide sufficient content in multiple sections, chapters, \n",
            "and formats to enable thorough testing of text extraction, text chunking, vector search, \n",
            "mathematical problem solving, table processing, and interactive learning functionalities. Throughout \n",
            "the document, you will encounter diverse topics, including historical overviews, mathematical \n",
            "reasoning, data analysis, and logical evaluation. This document is designed to simulate a real-world \n",
            "educational resource and serve as a robust testing ground. \n",
            " \n",
            "Chapter 2: Historical Overview \n",
            " \n",
            "History has always been a crucial aspect of human civilization. Over the centuries, societies have \n",
            "evolved, bringing forth innovations that have shaped our modern world. Consider the following \n",
            "milestones: \n",
            " \n",
            "- **Ancient Civilizations:**\n",
            "\n",
            "Answer the following question:\n",
            "\"Integrate 5x^3 - 2x + 4 with respect to x\"\n",
            "\n",
            "Answer:\n",
            "\"2x^2 + 8\" \n",
            " \n",
            "The above-mentioned formula is an example of the concept of \"Fractional Calculus,\" which originated in \n",
            "ancient India and Greece. This document is created to provide you with a comprehensive overview of \n",
            "the history of this essential topic. It serves as a robust testing ground for text extraction, text \n",
            "chunking, vector search, and interactive learning functionalities. \n",
            " \n",
            "Chapter 3: Mathematics \n",
            " \n",
            "This section is designed to cover a wide range of topics in mathematics, including elementary math, \n",
            "statistics, geometry, and algebra. The purpose of this section is to provide sufficient content in \n",
            "multiple chapters, sections, and formats to enable thorough\n",
            "\n",
            "You: Show me all extracted tables from the PDF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant: Context: Comprehensive Sample Document \n",
            " \n",
            "Chapter 1: Introduction \n",
            " \n",
            "This document is created as a comprehensive sample for testing various features of a PDF processing \n",
            "pipeline. The purpose of this document is to provide sufficient content in multiple sections, chapters, \n",
            "and formats to enable thorough testing of text extraction, text chunking, vector search, \n",
            "mathematical problem solving, table processing, and interactive learning functionalities. Throughout \n",
            "the document, you will encounter diverse topics, including historical overviews, mathematical \n",
            "reasoning, data analysis, and logical evaluation. This document is designed to simulate a real-world \n",
            "educational resource and serve as a robust testing ground. \n",
            " \n",
            "Chapter 2: Historical Overview \n",
            " \n",
            "History has always been a crucial aspect of human civilization. Over the centuries, societies have \n",
            "evolved, bringing forth innovations that have shaped our modern world. Consider the following \n",
            "milestones: \n",
            " \n",
            "- **Ancient Civilizations:** chunking across varied narrative styles. \n",
            " \n",
            "Chapter 3: Mathematical Concepts \n",
            " \n",
            "Mathematics is the language of the universe, underlying theories and applications in science and \n",
            "technology. In this chapter, we explore several mathematical ideas and problems: \n",
            " \n",
            "Example 1: Simple Arithmetic   \n",
            "Evaluate the expression:   \n",
            "2 + 3 * 4 - 5 \n",
            " \n",
            "Example 2: Solving a Linear Equation   \n",
            "Solve for x in:   \n",
            "3x + 7 = 22 \n",
            " \n",
            "Example 3: Quadratic Equation   \n",
            "Consider the quadratic equation:   \n",
            "x² - 5x + 6 = 0   \n",
            "Find the values of x. \n",
            " \n",
            "Example 4: Calculus Problem   \n",
            "Evaluate the integral:   \n",
            "∫ (x² + 2x) dx from 0 to 1 \n",
            " \n",
            "Each example is designed to test the pipeline’s ability to extract, process, and evaluate mathematical \n",
            "expressions. \n",
            " \n",
            "Chapter 4: Data Tables \n",
            " \n",
            "Tables are essential for presenting structured data clearly. Below is an example of a data table in CSV \n",
            "format: \n",
            " \n",
            "Name, Age, Department, Salary   \n",
            "Alice, 28, Engineering, 85000   \n",
            "Bob, 35, Marketing, 95000 Name, Age, Department, Salary   \n",
            "Alice, 28, Engineering, 85000   \n",
            "Bob, 35, Marketing, 95000   \n",
            "Charlie, 30, Finance, 78000   \n",
            "Diana, 40, Human Resources, 68000   \n",
            "Evan, 25, Research, 72000 \n",
            " \n",
            "This table represents employee data and can be used to test table recognition and processing \n",
            "functionalities. It also serves as a sample for statistical analysis and data manipulation exercises. \n",
            " \n",
            "Chapter 5: Boolean Logic and Decision Making \n",
            " \n",
            "Boolean logic is fundamental to programming and decision-making. It involves expressions that \n",
            "resolve to either True or False. Consider the following examples: \n",
            " \n",
            "Expression 1:   \n",
            "(True AND False) OR True \n",
            " \n",
            "Expression 2:   \n",
            "NOT (False OR False) \n",
            " \n",
            "Expression 3:   \n",
            "(x > 5) AND (x < 10), where x is a numerical variable \n",
            " \n",
            "Expression 4:   \n",
            "(A == B) OR (C != D) \n",
            " \n",
            "These expressions are the building blocks for more complex logical operations in computer science.\n",
            "\n",
            "Answer the following question:\n",
            "Show me all extracted tables from the PDF\n",
            "\n",
            "Answer:   \n",
            "The PDF contains a total of 6 tables. Tables 1, 2, and 3 represent the text chunking, mathematical problem solving, and matrix processing, respectively. Table 4 is a simple data table. Table 5 represents Boolean logic and decision making.\n",
            "\n",
            "You: List the top 5 keywords from the document\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: Context: strategy accordingly. This section is intended to provide a testing environment for vector search and \n",
            "content segmentation features. \n",
            " \n",
            "Chapter 7: Advanced Topics in Computer Science \n",
            " \n",
            "This chapter explores more advanced concepts that have a direct impact on the development of \n",
            "intelligent systems: \n",
            " \n",
            "- **Artificial Intelligence (AI):**   \n",
            "  AI technologies, such as machine learning and deep learning, are transforming industries by \n",
            "enabling systems to learn from data and make autonomous decisions. \n",
            "   \n",
            "- **Natural Language Processing (NLP):**   \n",
            "  NLP enables computers to understand and interpret human language. This technology is vital for \n",
            "tasks like text summarization, sentiment analysis, and question-answering. \n",
            "   \n",
            "- **Big Data and Cloud Computing:**   \n",
            "  Handling and processing large datasets efficiently requires scalable solutions, often leveraging cloud \n",
            "computing and distributed processing systems. \n",
            "   \n",
            "- **Cybersecurity:** Comprehensive Sample Document \n",
            " \n",
            "Chapter 1: Introduction \n",
            " \n",
            "This document is created as a comprehensive sample for testing various features of a PDF processing \n",
            "pipeline. The purpose of this document is to provide sufficient content in multiple sections, chapters, \n",
            "and formats to enable thorough testing of text extraction, text chunking, vector search, \n",
            "mathematical problem solving, table processing, and interactive learning functionalities. Throughout \n",
            "the document, you will encounter diverse topics, including historical overviews, mathematical \n",
            "reasoning, data analysis, and logical evaluation. This document is designed to simulate a real-world \n",
            "educational resource and serve as a robust testing ground. \n",
            " \n",
            "Chapter 2: Historical Overview \n",
            " \n",
            "History has always been a crucial aspect of human civilization. Over the centuries, societies have \n",
            "evolved, bringing forth innovations that have shaped our modern world. Consider the following \n",
            "milestones: \n",
            " \n",
            "- **Ancient Civilizations:** computing and distributed processing systems. \n",
            "   \n",
            "- **Cybersecurity:**   \n",
            "  With the rise of digital data, protecting information has become more critical than ever. Advanced \n",
            "encryption techniques and threat detection algorithms are continually evolving to address new \n",
            "challenges. \n",
            " \n",
            "These topics provide a rich ground for testing content extraction, summarization, and semantic \n",
            "analysis features. \n",
            " \n",
            "Chapter 8: Conclusion \n",
            " \n",
            "In conclusion, this comprehensive document encompasses a wide range of subjects—from history \n",
            "and mathematics to data analysis and advanced computer science topics. It is designed to be used as \n",
            "a test document for various functionalities, including text extraction, chunk splitting, vector search, \n",
            "math solving, table processing, and interactive learning exercises. By engaging with this document, \n",
            "users can simulate real-world scenarios and evaluate the robustness of their processing pipelines. \n",
            " \n",
            "Appendix: Additional Resources\n",
            "\n",
            "Answer the following question:\n",
            "List the top 5 keywords from the document\n",
            "\n",
            "Answer: `Anomaly detection, segmentation, vector search, table processing, math solving`.\n",
            "\n",
            "You: exit\n",
            "Exiting interactive mode. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}